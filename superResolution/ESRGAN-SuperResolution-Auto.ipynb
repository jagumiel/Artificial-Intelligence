{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    #folder = \"reprDatasetImages\"\n",
    "    folder = \"/myReprDataset/\"\n",
    "    image_size = 100\n",
    "    raw_test_data = []\n",
    "\n",
    "    files = glob.glob(folder+'/*.jpg')\n",
    "    for file in files:\n",
    "        image = Image.open(file)\n",
    "        image = image.convert(\"RGB\")\n",
    "        image = image.resize((image_size, image_size))\n",
    "        #Quantizing the image between -1,1;\n",
    "        image = (2.0 / 255.0) * np.float32(image) - 1.0\n",
    "        #image = np.asarray(image).astype(np.float32)\n",
    "        image = image[np.newaxis,:,:,:]\n",
    "        raw_test_data.append(image)\n",
    "\n",
    "    for data in raw_test_data:\n",
    "        yield [data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.load(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\")\n",
    "concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "concrete_func.inputs[0].set_shape([1, 100, 100, 3])\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "#I don't see the following flags making any different effect.\n",
    "converter.experimental_new_converter = True\n",
    "converter.experimental_new_quantizer = True\n",
    "\n",
    "converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.float32\n",
    "converter.allow_custom_ops = False\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TF Lite model.\n",
    "with tf.io.gfile.GFile('ESRGAN_Quant.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "esrgan_model_path = './ESRGAN_Quant.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = tf.keras.utils.get_file('lr.jpg', 'https://raw.githubusercontent.com/tensorflow/examples/master/lite/examples/super_resolution/android/app/src/main/assets/lr-1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "esrgan_model_path = './ESRGAN.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = cv2.imread('/home/jose/codeWorkspace-2.4.1/tf_2.4.1/superResolution/myReprDataset/000000003501_100x100.jpg')\n",
    "#lr = cv2.imread('/home/jose/codeWorkspace-2.4.1/tf_2.4.1/superResolution/myReprDataset/cayman.jpg')\n",
    "lr = cv2.cvtColor(lr, cv2.COLOR_BGR2RGB)\n",
    "lr = tf.expand_dims(lr, axis=0)\n",
    "lr = tf.cast(lr, tf.float32)\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=esrgan_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Run the model\n",
    "interpreter.set_tensor(input_details[0]['index'], lr)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Extract the output and postprocess it\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "sr = tf.squeeze(output_data, axis=0)\n",
    "sr = tf.clip_by_value(sr, 0, 255)\n",
    "sr = tf.round(sr)\n",
    "sr = tf.cast(sr, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.cast(tf.squeeze(lr, axis=0), tf.uint8)\n",
    "plt.figure(figsize = (1, 1))\n",
    "plt.title('LR')\n",
    "plt.imshow(lr.numpy());\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)        \n",
    "plt.title(f'ESRGAN (x4)')\n",
    "plt.imshow(sr.numpy());\n",
    "\n",
    "bicubic = tf.image.resize(lr, [1024, 1024], tf.image.ResizeMethod.BICUBIC)\n",
    "bicubic = tf.cast(bicubic, tf.uint8)\n",
    "plt.subplot(1, 2, 2)   \n",
    "plt.title('Bicubic')\n",
    "plt.imshow(bicubic.numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-passenger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2975056882626c520bf9a133dcb2ee133f67336c0c66748e4de61a4a8fa6165"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
